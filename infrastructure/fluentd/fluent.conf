# BarnHand Fluentd Configuration
# Collects and processes logs from all BarnHand services

<system>
  log_level info
  suppress_repeated_stacktrace true
  emit_error_log_interval 30s
  suppress_config_dump
  without_source true
</system>

# Prometheus metrics endpoint
<source>
  @type prometheus
  @id prometheus_metrics
  bind 0.0.0.0
  port 9880
  metrics_path /metrics
</source>

<source>
  @type prometheus_output_monitor
  @id prometheus_output_monitor
</source>

# Forward input for Docker containers
<source>
  @type forward
  @id forward_input
  port 24224
  bind 0.0.0.0
  
  <security>
    self_hostname fluentd
    shared_key barnhand_logs_secret_key
  </security>
</source>

# Docker container logs input
<source>
  @type tail
  @id docker_container_logs
  path /var/lib/docker/containers/*/*-json.log
  pos_file /fluentd/log/docker-containers.log.pos
  tag docker.*
  format json
  read_from_head true
  
  <parse>
    @type json
    time_format %Y-%m-%dT%H:%M:%S.%NZ
    time_key time
    keep_time_key false
  </parse>
</source>

# Parse Docker container logs and add metadata
<filter docker.**>
  @type parser
  @id docker_log_parser
  key_name log
  reserve_data true
  remove_key_name_field true
  emit_invalid_record_to_error false
  
  <parse>
    @type multi_format
    
    <pattern>
      format json
    </pattern>
    
    <pattern>
      format regexp
      expression /^(?<timestamp>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}Z)\s+\[(?<level>\w+)\]:\s+(?<message>.*)$/
    </pattern>
    
    <pattern>
      format regexp
      expression /^(?<timestamp>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\s+(?<level>\w+)\s+(?<message>.*)$/
    </pattern>
    
    <pattern>
      format none
    </pattern>
  </parse>
</filter>

# Add Docker container metadata
<filter docker.**>
  @type record_modifier
  @id docker_metadata
  
  <record>
    hostname ${hostname}
    source fluentd
    environment production
  </record>
  
  # Extract container name from source
  <ruby>
    tag_parts = tag.split('.')
    if tag_parts.length >= 2
      container_id = tag_parts[1]
      
      # Try to get container name from Docker API or file system
      # This is a simplified approach - in production you might want to use docker API
      if container_id.length == 64  # Docker container ID length
        record['container_id'] = container_id[0,12]  # Short ID
      end
    end
  </ruby>
</filter>

# Tag routing based on container names and log levels
<match docker.**>
  @type rewrite_tag_filter
  @id docker_tag_routing
  
  <rule>
    key container_name
    pattern /api-gateway/
    tag barnhand.api_gateway
  </rule>
  
  <rule>
    key container_name
    pattern /ml-service/
    tag barnhand.ml_service
  </rule>
  
  <rule>
    key container_name
    pattern /stream-service/
    tag barnhand.stream_service
  </rule>
  
  <rule>
    key container_name
    pattern /video-streamer/
    tag barnhand.video_streamer
  </rule>
  
  <rule>
    key container_name
    pattern /frontend/
    tag barnhand.frontend
  </rule>
  
  <rule>
    key container_name
    pattern /postgres/
    tag barnhand.database
  </rule>
  
  <rule>
    key container_name
    pattern /redis/
    tag barnhand.cache
  </rule>
  
  <rule>
    key container_name
    pattern /nginx/
    tag barnhand.proxy
  </rule>
  
  <rule>
    key container_name
    pattern /.*/
    tag barnhand.other
  </rule>
</match>

# Error log filtering and alerting
<filter barnhand.**>
  @type grep
  @id error_filter
  
  <regexp>
    key level
    pattern /(ERROR|FATAL|CRITICAL)/i
  </regexp>
</filter>

# Performance monitoring for ML service
<filter barnhand.ml_service>
  @type record_modifier
  @id ml_service_metrics
  
  <ruby>
    # Extract performance metrics from ML service logs
    if record['message'] && record['message'].include?('Processing time:')
      match = record['message'].match(/Processing time: (\d+\.?\d*)ms/)
      if match
        record['processing_time_ms'] = match[1].to_f
        record['metric_type'] = 'performance'
      end
    end
    
    if record['message'] && record['message'].include?('Detection accuracy:')
      match = record['message'].match(/Detection accuracy: (\d+\.?\d*)%/)
      if match
        record['detection_accuracy'] = match[1].to_f
        record['metric_type'] = 'accuracy'
      end
    end
    
    if record['message'] && record['message'].include?('GPU utilization:')
      match = record['message'].match(/GPU utilization: (\d+\.?\d*)%/)
      if match
        record['gpu_utilization'] = match[1].to_f
        record['metric_type'] = 'resource'
      end
    end
  </ruby>
</filter>

# Stream processing metrics
<filter barnhand.stream_service>
  @type record_modifier
  @id stream_service_metrics
  
  <ruby>
    if record['message'] && record['message'].include?('Chunk processed:')
      record['metric_type'] = 'chunk_processing'
      
      # Extract chunk processing details
      if record['message'].include?('duration:')
        match = record['message'].match(/duration: (\d+\.?\d*)s/)
        if match
          record['chunk_duration'] = match[1].to_f
        end
      end
      
      if record['message'].include?('size:')
        match = record['message'].match(/size: (\d+\.?\d*)(MB|KB)/)
        if match
          size = match[1].to_f
          unit = match[2]
          record['chunk_size_mb'] = unit == 'KB' ? size / 1024 : size
        end
      end
    end
  </ruby>
</filter>

# Database connection monitoring
<filter barnhand.database>
  @type record_modifier
  @id database_monitoring
  
  <ruby>
    if record['message'] && (record['message'].include?('connection') || record['message'].include?('query'))
      record['metric_type'] = 'database'
      
      # Extract connection count
      if record['message'].include?('connection count:')
        match = record['message'].match(/connection count: (\d+)/)
        if match
          record['connection_count'] = match[1].to_i
        end
      end
      
      # Extract slow query information
      if record['message'].include?('slow query')
        record['alert_type'] = 'slow_query'
        record['severity'] = 'warning'
      end
    end
  </ruby>
</filter>

# Output to PostgreSQL for storage
<match barnhand.**>
  @type postgresql
  @id postgresql_output
  
  host postgres
  port 5432
  database barnhand
  username admin
  password "#{ENV['POSTGRES_PASSWORD']}"
  
  # Use connection pooling
  connection_pool_size 10
  connection_pool_timeout 5
  
  # Table structure for logs
  table logs
  
  # Buffer configuration for performance
  <buffer>
    @type file
    path /fluentd/buffer/postgresql
    chunk_limit_size 1MB
    total_limit_size 1GB
    flush_interval 10s
    retry_forever true
    retry_max_interval 30s
  </buffer>
  
  # Log schema mapping
  <format>
    @type json
  </format>
  
  # Create table if not exists
  auto_create_table true
  
  # Table schema
  <table>
    timestamp TIMESTAMPTZ
    level VARCHAR(10)
    service VARCHAR(50)
    container_id VARCHAR(20)
    message TEXT
    raw_log TEXT
    metadata JSONB
  </table>
</match>

# Output metrics to Prometheus (via file)
<match barnhand.**>
  @type copy
  
  <store>
    @type file
    @id file_output_metrics
    path /fluentd/log/metrics
    append true
    time_slice_format %Y%m%d%H
    
    <format>
      @type json
    </format>
    
    <buffer time>
      timekey 3600
      timekey_wait 10m
    </buffer>
    
    # Only output records with metrics
    <filter>
      @type grep
      <regexp>
        key metric_type
        pattern /.+/
      </regexp>
    </filter>
  </store>
</match>

# Error alerting output
<match barnhand.**>
  @type copy
  
  <store>
    @type file
    @id file_output_errors
    path /fluentd/log/errors
    append true
    
    <format>
      @type json
    </format>
    
    <buffer>
      @type file
      path /fluentd/buffer/errors
      flush_interval 5s
    </buffer>
    
    # Only output error-level logs
    <filter>
      @type grep
      <regexp>
        key level
        pattern /(ERROR|FATAL|CRITICAL)/i
      </regexp>
    </filter>
  </store>
</match>

# Debug output (can be disabled in production)
<match **>
  @type stdout
  @id stdout_output
  
  <format>
    @type json
  </format>
  
  # Only in development/debug mode
  # Comment out for production
</match>