# Phase 2: ML Chunk Processing Task List

## Phase 0: Map Current System âœ… COMPLETE

- [x] Document current video playback flow - find where videos are served
- [x] Find video serving endpoint (api-gateway/routes)
- [x] Find frontend video URL construction
- [x] Find chunk storage/retrieval logic
- [x] Output findings to `CURRENT_VIDEO_FLOW.md`
- [x] Update the following tasks as needed to ensure well aligned with current

## Phase 1: ML Service Core

### 1.1 ChunkProcessor

- [ ] Create `backend/ml-service/src/services/chunk_processor.py`
- [ ] Port `AdvancedStatePipeline` from `test_advanced_state_pipeline.py`
- [ ] Accept: chunk_id, chunk_path, farm_id, stream_id
- [ ] Output processed video to: `/chunks/{farmId}/{streamId}/processed/{chunkId}_processed.mp4`
- [ ] Output JSON to: `/chunks/{farmId}/{streamId}/detections/{chunkId}_detections.json`
- [ ] JSON schema: video_metadata, summary, horses[], frames[] with full detection data
- [ ] Test standalone processing

### 1.2 ML Service Endpoint

- [ ] Add `POST /api/process-chunk` to `backend/ml-service/src/main.py`
- [ ] Accept: chunk_id, chunk_path, farm_id, stream_id
- [ ] Call ChunkProcessor
- [ ] Return: processed_video_path, detections_path, status, summary
- [ ] Test with curl

### 1.3 Verify Models

- [ ] Test YOLO loads in Docker
- [ ] Test RTMPose loads in Docker
- [ ] Test MegaDescriptor ReID loads in Docker
- [ ] Check `docker-compose logs ml-service`

## Phase 2: API Gateway Integration

### 2.1 Database Schema

- [ ] Add columns to video_chunks table:
  - [ ] processed_video_path TEXT
  - [ ] detections_path TEXT
  - [ ] ml_processed BOOLEAN DEFAULT FALSE
  - [ ] processing_status TEXT
  - [ ] processing_time_seconds FLOAT
- [ ] Run migration
- [ ] Test insert

### 2.2 Update Record-Chunk

- [ ] Modify `backend/api-gateway/src/routes/streams.ts`
- [ ] Save raw chunk, create DB record with ml_processed=false
- [ ] Call ML service async: `POST http://ml-service:8002/api/process-chunk`
- [ ] Update DB when ML completes: paths, ml_processed=true, processing_status='complete'
- [ ] Return chunk_id immediately
- [ ] Test recording triggers ML

### 2.3 Modify Video Serving (CRITICAL)

- [x] Find current video serving endpoint - `videoChunkService.ts:479-488` (Phase 0)
- [ ] Add `/chunks` endpoint to video-streamer service
- [ ] Modify `getChunkStreamUrl()` to check ml_processed flag
- [ ] If ml_processed=true, serve from `/chunks/{farmId}/{streamId}/processed/`
- [ ] Else serve from `/chunks/{farmId}/{streamId}/raw/`
- [ ] Add query param `?raw=true` to force raw video
- [ ] Test: processed video served when available
- [ ] Test: `?raw=true` serves raw video

### 2.4 Add Detections Endpoint

- [ ] Create `GET /api/v1/chunks/:chunkId/detections`
- [ ] Read JSON from detections_path
- [ ] Return full JSON
- [ ] Test with curl

### 2.5 Add Status Endpoint

- [ ] Create `GET /api/v1/chunks/:chunkId/status`
- [ ] Return: chunk_id, ml_processed, processing_status
- [ ] Test status during and after processing

## Phase 3: Frontend Display

### 3.1 Update Video URL Logic

- [ ] Find current video URL construction
- [ ] Check processing status before building URL
- [ ] Use same endpoint (backend now serves processed automatically)
- [ ] Add `?raw=true` when raw toggle is on
- [ ] Test: video switches from raw to processed

### 3.2 Update VideoPlayer Component

- [ ] Add "Show Raw Video" toggle to `frontend/src/components/VideoPlayer.tsx`
- [ ] When on: append `?raw=true` to video URL
- [ ] Add processing status badge: "ðŸ”„ Processing..." or "âœ“ Processed"
- [ ] Test toggle switches between raw/processed

### 3.3 Create Detection Data Panel

- [ ] Create `frontend/src/components/DetectionDataPanel.tsx`
- [ ] Fetch: `GET /api/v1/chunks/${chunkId}/detections`
- [ ] Display summary: horse count, processing time, frame count
- [ ] Display horse list: ID, color, state distribution, confidence
- [ ] Add frame timeline scrubber
- [ ] Add collapsible raw JSON view
- [ ] Test: displays all detection data

### 3.4 Update Chunk List Status

- [ ] Modify chunk list component
- [ ] Show status badge: Processing/Processed/Failed/Raw
- [ ] Poll status every 2s while processing
- [ ] Display processing time
- [ ] Test: status updates in real-time

### 3.5 Add Download Options

- [ ] Add download buttons: Processed video, Raw video, Detections JSON
- [ ] Test downloads

## Phase 4: Testing & Polish

### 4.1 End-to-End Video Playback

- [ ] Start docker-compose
- [ ] Record 5 second chunk
- [ ] Verify: plays raw immediately
- [ ] Wait for processing
- [ ] Verify: automatically switches to processed (overlays visible)
- [ ] Toggle "Show Raw"
- [ ] Verify: raw video displays (no overlays)
- [ ] Toggle off
- [ ] Verify: processed video returns

### 4.2 End-to-End Detection Data

- [ ] Open processed chunk
- [ ] Verify: detection panel shows summary
- [ ] Verify: horse list displays
- [ ] Verify: timeline scrubber works
- [ ] Click timeline points
- [ ] Verify: video jumps to frame
- [ ] Expand raw JSON
- [ ] Verify: full data visible
- [ ] Download detections JSON
- [ ] Verify: file contains frame data

### 4.3 Performance

- [ ] Make ML processing async
- [ ] Add Redis processing queue
- [ ] Auto-refresh when processing completes
- [ ] Cache processed videos
- [ ] Set 30s processing timeout
- [ ] Test multiple concurrent recordings

### 4.4 Error Handling

- [ ] Handle ML service down - show "Processing unavailable"
- [ ] Handle processing timeout - mark failed after 60s
- [ ] Handle missing models - graceful degradation
- [ ] Handle corrupted video - catch errors, mark failed
- [ ] Log errors with correlation IDs
- [ ] Test each error scenario

### 4.5 Documentation

- [ ] Update README with video playback flow
- [ ] Create `VIDEO_PLAYBACK.md`
- [ ] Add code comments to video serving logic

## Definition of Done

- [ ] Record chunk â†’ ML processes automatically
- [ ] Video plays raw immediately, switches to processed when ready
- [ ] Processed video shows: bounding boxes, IDs, pose keypoints
- [ ] Horse IDs persist across chunks
- [ ] Detection panel displays: count, states, timeline, JSON
- [ ] Toggle between raw/processed views
- [ ] Processing status visible
- [ ] Processing <30s for 10s chunk
- [ ] End-to-end test passes

---

## Last Work Session Notes

**Date**: 2025-10-06 (Session 1)

**Completed Tasks**:

- [x] Phase 0.1 - Documented current video playback flow
- [x] Phase 0.2 - Found video serving endpoint in `backend/api-gateway/src/routes/streams.ts`
- [x] Phase 0.3 - Found frontend video URL construction in `VideoPlayer.tsx` and `StreamCard.tsx`
- [x] Phase 0.4 - Found chunk storage/retrieval logic in `videoChunkService.ts`
- [x] Phase 0.5 - Created comprehensive `CURRENT_VIDEO_FLOW.md` documentation

**Current Status**:
Phase 0 is **100% complete**. The current video flow has been fully mapped and documented.

**Key Findings**:

1. **Two separate video systems exist**:
   - Live HLS streaming (video-streamer â†’ HLS.js)
   - Recorded chunks (FFmpeg recording â†’ direct MP4 playback)

2. **Critical endpoint identified**: `videoChunkService.getChunkStreamUrl()` at line 479-488
   - Currently returns: `http://localhost:8003/chunks/{farmId}/{streamId}/{filename}`
   - This endpoint doesn't exist and needs to be created
   - **Phase 2 will modify this to serve raw vs processed videos**

3. **Working ML pipeline exists**: `backend/ml-service/test_advanced_state_pipeline.py`
   - Contains complete YOLO + RTMPose + ReID + State Detection
   - Will be ported to `ChunkProcessor` service

4. **Storage structure defined**:
   ```
   /chunks/{farmId}/{streamId}/raw/
   /chunks/{farmId}/{streamId}/processed/
   /chunks/{farmId}/{streamId}/detections/
   ```

**Next Priority**:
**Start Phase 1.1 - Create ChunkProcessor**

- Port `AdvancedStatePipeline` from `test_advanced_state_pipeline.py`
- Create `backend/ml-service/src/services/chunk_processor.py`
- Accept: chunk_id, chunk_path, farm_id, stream_id
- Output: processed video + detections JSON
- Test standalone before API integration

**Blockers/Issues**:
None. System is well-documented and ready for Phase 1 implementation.

**Testing Notes**:
Docker services are running:

- postgres: healthy
- redis: healthy
- ml-service: healthy (port 8002)
- api-gateway: unhealthy (needs investigation, but not blocking Phase 1)
- video-streamer: healthy (port 8003)
- stream-service: healthy (port 8001)
- frontend: running (port 3000)

**Implementation Notes**:

1. Do NOT create parallel video systems - modify existing endpoints
2. Async processing is critical - chunk recording must return immediately
3. Use `test_advanced_state_pipeline.py` as reference implementation
4. Database schema changes will come in Phase 2.1
5. Frontend changes will come in Phase 3

**Handoff Context**:
The next session should:

1. Read `CURRENT_VIDEO_FLOW.md` to understand the system
2. Review `backend/ml-service/test_advanced_state_pipeline.py` (lines 1-100 shown earlier)
3. Create `backend/ml-service/src/services/chunk_processor.py`
4. Port the `AdvancedStatePipeline` class with proper FastAPI integration
5. Focus on making ChunkProcessor work standalone first before API integration
