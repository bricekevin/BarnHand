#!/usr/bin/env python3
"""
Quick Test Script for Deep ReID Performance
Tests the ReID system on first 200 frames to validate implementation
"""

import os
import sys
import cv2
import numpy as np
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision import models
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, field
from collections import deque
import time
from scipy.spatial.distance import cosine

# Set environment
os.environ['LOG_LEVEL'] = 'INFO'
os.environ['CONFIDENCE_THRESHOLD'] = '0.7'
os.environ['MODEL_PATH'] = '../../models'
os.environ['YOLO_MODEL'] = 'downloads/yolov5m.pt'

sys.path.insert(0, 'src')

class QuickReIDExtractor:
    """Simple CNN feature extractor for testing."""
    
    def __init__(self, device='cpu'):
        self.device = torch.device(device)
        
        # Load pre-trained ResNet18 (faster than ResNet50 for testing)
        self.base_model = models.resnet18(pretrained=True)
        
        # Remove final classification layer
        self.feature_extractor = nn.Sequential(
            *list(self.base_model.children())[:-1]
        )
        self.feature_extractor.eval()
        self.feature_extractor.to(self.device)
        
        # Standard preprocessing
        self.preprocess = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224, 224)),  # Standard size
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        print("‚úÖ Quick ReID extractor initialized (ResNet18)")
    
    def extract_features(self, image_crop: np.ndarray) -> np.ndarray:
        """Extract 512-dim features from horse crop."""
        if image_crop.size == 0:
            return np.zeros(512)
        
        try:
            with torch.no_grad():
                # Convert BGR to RGB
                image_rgb = cv2.cvtColor(image_crop, cv2.COLOR_BGR2RGB)
                
                # Preprocess
                input_tensor = self.preprocess(image_rgb)
                input_batch = input_tensor.unsqueeze(0).to(self.device)
                
                # Extract features
                features = self.feature_extractor(input_batch)
                features = features.squeeze().cpu().numpy()
                
                # L2 normalize
                features = features / (np.linalg.norm(features) + 1e-6)
                
                return features
        except Exception as e:
            print(f"Feature extraction error: {e}")
            return np.zeros(512)

@dataclass
class QuickHorse:
    """Simple horse representation for testing."""
    horse_id: int
    color: Tuple[int, int, int]
    features: List[np.ndarray] = field(default_factory=list)
    max_features: int = 10
    detection_count: int = 0
    last_bbox: Optional[Dict] = None
    
    def add_features(self, features: np.ndarray):
        """Add features to horse gallery."""
        self.detection_count += 1
        
        if len(self.features) >= self.max_features:
            # Replace oldest
            self.features.pop(0)
        self.features.append(features)
    
    def get_avg_features(self) -> np.ndarray:
        """Get average features."""
        if not self.features:
            return np.zeros(512)
        return np.mean(self.features, axis=0)

class QuickReIDTracker:
    """Simple ReID tracker for testing."""
    
    COLORS = [
        (255, 100, 100),  # Light blue - Horse 1
        (100, 255, 100),  # Light green - Horse 2  
        (100, 100, 255),  # Light red - Horse 3
        (255, 255, 100),  # Cyan - Horse 4
        (255, 100, 255),  # Magenta - Horse 5
        (100, 255, 255),  # Yellow - Horse 6
    ]
    
    def __init__(self, max_horses=3, similarity_threshold=0.7):
        self.horses: Dict[int, QuickHorse] = {}
        self.next_id = 1
        self.max_horses = max_horses
        self.similarity_threshold = similarity_threshold
        self.feature_extractor = QuickReIDExtractor()
        
        # Stats
        self.total_detections = 0
        self.force_matches = 0
        self.new_horses_created = 0
        self.successful_matches = 0
        
    def match_detection(self, frame: np.ndarray, bbox: Dict) -> QuickHorse:
        """Match detection to horse or create new."""
        self.total_detections += 1
        
        # Extract crop
        x, y, w, h = int(bbox['x']), int(bbox['y']), int(bbox['width']), int(bbox['height'])
        x = max(0, min(x, frame.shape[1] - 1))
        y = max(0, min(y, frame.shape[0] - 1))
        w = min(w, frame.shape[1] - x)
        h = min(h, frame.shape[0] - y)
        
        if w > 0 and h > 0:
            horse_crop = frame[y:y+h, x:x+w]
            features = self.feature_extractor.extract_features(horse_crop)
        else:
            features = np.zeros(512)
        
        # Find best match
        best_horse = None
        best_similarity = 0.0
        
        for horse in self.horses.values():
            if len(horse.features) == 0:
                continue
                
            # Compare with average features
            avg_features = horse.get_avg_features()
            similarity = 1 - cosine(features, avg_features)
            
            if similarity > best_similarity:
                best_similarity = similarity
                best_horse = horse
        
        # Decision logic
        if len(self.horses) < self.max_horses:
            # Can create new horse
            if best_similarity >= self.similarity_threshold and best_horse:
                # Match to existing
                best_horse.add_features(features)
                best_horse.last_bbox = bbox
                self.successful_matches += 1
                return best_horse
            else:
                # Create new
                new_horse = QuickHorse(
                    horse_id=self.next_id,
                    color=self.COLORS[(self.next_id - 1) % len(self.COLORS)],
                    last_bbox=bbox
                )
                new_horse.add_features(features)
                self.horses[self.next_id] = new_horse
                self.next_id += 1
                self.new_horses_created += 1
                print(f"   üÜï Created Horse #{new_horse.horse_id} (total: {len(self.horses)})")
                return new_horse
        else:
            # At capacity - must match to existing
            if best_horse:
                best_horse.add_features(features)
                best_horse.last_bbox = bbox
                if best_similarity >= self.similarity_threshold:
                    self.successful_matches += 1
                else:
                    self.force_matches += 1
                    print(f"   ‚ö†Ô∏è Force-matched to Horse #{best_horse.horse_id} (sim: {best_similarity:.3f})")
                return best_horse
            else:
                # Fallback - shouldn't happen
                fallback_horse = list(self.horses.values())[0]
                fallback_horse.add_features(features)
                fallback_horse.last_bbox = bbox
                self.force_matches += 1
                return fallback_horse
    
    def get_stats(self):
        """Get tracking statistics."""
        return {
            'total_horses': len(self.horses),
            'total_detections': self.total_detections,
            'successful_matches': self.successful_matches,
            'force_matches': self.force_matches,
            'new_horses_created': self.new_horses_created,
            'match_rate': self.successful_matches / max(self.total_detections, 1),
            'force_rate': self.force_matches / max(self.total_detections, 1)
        }

def test_quick_reid():
    """Test ReID system on first 200 frames."""
    
    print("üß™ Quick ReID Test - 200 Frames")
    print("=" * 50)
    
    from src.models.detection import HorseDetectionModel
    
    # Load detection model
    print("üîß Loading detection model...")
    yolo_model = HorseDetectionModel()
    yolo_model.load_models()
    print("‚úÖ Detection model loaded")
    
    # Initialize tracker
    tracker = QuickReIDTracker(max_horses=3, similarity_threshold=0.7)
    
    # Video setup
    input_video = "../../media/rolling-on-ground.mp4"
    cap = cv2.VideoCapture(input_video)
    
    # Test parameters
    max_frames = 200  # Quick test
    
    print(f"üìπ Testing on first {max_frames} frames...")
    print(f"üéØ Goal: Keep horses at exactly 3")
    print()
    
    frame_horses = []  # Track horses per frame
    
    start_time = time.time()
    
    for frame_idx in range(max_frames):
        ret, frame = cap.read()
        if not ret:
            break
        
        # Detect horses
        detections, _ = yolo_model.detect_horses(frame)
        
        frame_horse_count = 0
        if detections:
            for detection in detections:
                # Match each detection
                horse = tracker.match_detection(frame, detection['bbox'])
                frame_horse_count += 1
        
        frame_horses.append(len(tracker.horses))
        
        # Progress
        if frame_idx % 50 == 0 and frame_idx > 0:
            stats = tracker.get_stats()
            print(f"   Frame {frame_idx}: {stats['total_horses']} horses, "
                  f"{stats['force_matches']} force matches")
    
    cap.release()
    elapsed = time.time() - start_time
    
    # Final analysis
    final_stats = tracker.get_stats()
    
    print(f"\nüìä Quick ReID Test Results:")
    print(f"   Processing time: {elapsed:.1f}s ({max_frames/elapsed:.1f} fps)")
    print(f"   Total detections: {final_stats['total_detections']}")
    print(f"   Final horse count: {final_stats['total_horses']} (target: 3)")
    print(f"   Horses created: {final_stats['new_horses_created']}")
    print(f"   Successful matches: {final_stats['successful_matches']}")
    print(f"   Force matches: {final_stats['force_matches']}")
    print(f"   Match rate: {final_stats['match_rate']:.1%}")
    print(f"   Force rate: {final_stats['force_rate']:.1%}")
    
    # Horse count progression
    max_horses_seen = max(frame_horses)
    avg_horses = np.mean(frame_horses)
    
    print(f"\nüêé Horse Count Analysis:")
    print(f"   Max horses at any time: {max_horses_seen}")
    print(f"   Average horses: {avg_horses:.1f}")
    print(f"   Final count: {frame_horses[-1]}")
    
    # Success assessment
    if final_stats['total_horses'] == 3:
        print(f"   ‚úÖ SUCCESS: Maintained exactly 3 horses!")
    elif final_stats['total_horses'] <= 5:
        print(f"   ‚ö†Ô∏è Good: Only {final_stats['total_horses']} horses (vs 13 before)")
    else:
        print(f"   ‚ùå Created {final_stats['total_horses']} horses - needs improvement")
    
    # Individual horse stats
    print(f"\nüèá Individual Horse Details:")
    for horse_id, horse in tracker.horses.items():
        print(f"   Horse #{horse_id}: {horse.detection_count} detections, "
              f"{len(horse.features)} features")
    
    return final_stats['total_horses']

def main():
    print("üß™ Quick ReID Implementation Test")
    print("=" * 60)
    print("Testing deep learning re-identification on 200 frames")
    print("Goal: Validate ReID approach and measure performance")
    print()
    
    try:
        num_horses = test_quick_reid()
        
        print(f"\nüéâ Test Complete!")
        if num_horses == 3:
            print("   üéØ PERFECT: ReID maintained exactly 3 horses!")
            print("   ‚úÖ Implementation is working correctly")
        elif num_horses <= 5:
            print(f"   ‚úÖ GOOD: Only {num_horses} horses created")
            print("   üìà Significant improvement over hand-crafted features")
        else:
            print(f"   ‚ùå Still created {num_horses} horses")
            print("   üîß Needs parameter tuning or different approach")
            
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())